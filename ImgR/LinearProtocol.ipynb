{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7c7133-5c79-45e8-b981-0e4b8ec87ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    \n",
    "SEED = 333\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40457112-62c0-41c7-80d4-b901ec4dbec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataload import get_inshop_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATASET_DIR = '../../../dataset/InShop/'\n",
    "all_data, label_enc, cat_enc, subcat_enc, vari_enc = get_inshop_dataset(root_path=DATASET_DIR)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid, cat_tr, cat_val = train_test_split(all_data, \n",
    "                                                            label_enc, \n",
    "                                                            cat_enc,\n",
    "                                                            test_size=0.15, \n",
    "                                                            random_state=SEED, \n",
    "                                                            stratify=cat_enc)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test, _, _ = train_test_split(X_valid, \n",
    "                                                            y_valid, \n",
    "                                                            cat_val,\n",
    "                                                            test_size=0.5, \n",
    "                                                            random_state=SEED, \n",
    "                                                            stratify=cat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7603e22-67e9-48ca-af3f-51791bbc9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import MyDataset, TransformsCE\n",
    "\n",
    "size = 224\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = MyDataset(img_list=X_train, \n",
    "                          label_list=y_train, \n",
    "                          phase='train', \n",
    "                          transform=TransformsCE(size))\n",
    "\n",
    "val_dataset = MyDataset(img_list=X_valid, \n",
    "                          label_list=y_valid, \n",
    "                          phase='val', \n",
    "                          transform=TransformsCE(size))\n",
    "\n",
    "test_dataset = MyDataset(img_list=X_test, \n",
    "                          label_list=y_test, \n",
    "                          phase='test', \n",
    "                          transform=TransformsCE(size))\n",
    "\n",
    "image_datasets = {'train' : train_dataset, 'val' : val_dataset, 'test': test_dataset}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "                                                                                                                                             \n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "dataloaders = {'train': train_dataloader, 'val': val_dataloader, 'test': test_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bae92a-8807-4999-bdfc-34eb892e2d68",
   "metadata": {},
   "source": [
    "-----\n",
    "### HIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3cccca-5de9-4264-b9db-af8b00792f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0 - DeepFashion-pre-linear / ResNet50-HIE-33-400-linear\n"
     ]
    }
   ],
   "source": [
    "SEED = 333\n",
    "seed_everything(SEED)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "MODEL_PATH = '../../../pretrained/ResNet50-HIE-33+300-400.pth'\n",
    "SAVE_PATH = '../../../weights'\n",
    "\n",
    "RUN_NAME = 'ResNet50-HIE-33-400-linear'\n",
    "WANDB_PRJ = 'DeepFashion-pre-linear'\n",
    "\n",
    "CONFIG = {\n",
    "    \"dataset\": \"DeepFashion\",\n",
    "    \"machine\": \"offline cluster\",\n",
    "    \"model\": \"ResNet50-HIE\",\n",
    "    \"learning_rate\": 0.2,\n",
    "    \"batch_size\": batch_size*2\n",
    "}\n",
    "\n",
    "print(f'Training on {device} - {WANDB_PRJ} / {RUN_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e02124-4f79-40cb-b1e1-1766cf22d09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-02.\n",
      "Epoch 00000: adjusting learning rate of group 0 to 2.0000e-01.\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.models import MLP\n",
    "from src.optim_lars import LARS\n",
    "\n",
    "num_classes = 0\n",
    "model = timm.create_model('resnet50', pretrained=False, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "mlp = MLP(num_classes=17) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = LARS(\n",
    "    list(mlp.parameters()),\n",
    "    lr=0.2,\n",
    "    weight_decay=1e-6,\n",
    "    exclude_from_weight_decay=['batch_normalization', 'bias'],\n",
    ")\n",
    "\n",
    "warmupscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch : (epoch+1)/10.0, verbose = True)\n",
    "mainscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 500, eta_min=0.05, last_epoch=-1, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de5c42-0dc2-46ef-9557-13cfb6a95e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m33h002\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/soohee/Workspace/cv/git/MLDL-Prj/ImgR/wandb/run-20221129_212324-nw0kc0lj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/33h002/DeepFashion-pre-linear/runs/nw0kc0lj\" target=\"_blank\">ResNet50-HIE-33-400-linear</a></strong> to <a href=\"https://wandb.ai/33h002/DeepFashion-pre-linear\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.0000e-02.\n",
      "e: 1 | Train Loss: 149824.8254 | 3.3439 | Acc: 0.6641\n",
      "e: 1 | Valid Loss: 9653.5415 | 2.4421 | Acc: 0.7293\n",
      "Validation loss decreased (inf --> 9653.541527).\n",
      "Adjusting learning rate of group 0 to 6.0000e-02.\n",
      "e: 2 | Train Loss: 100262.6889 | 2.2378 | Acc: 0.7816\n",
      "e: 2 | Valid Loss: 8987.4838 | 2.2736 | Acc: 0.7442\n",
      "Validation loss decreased (9653.541527 --> 8987.483818).\n",
      "Adjusting learning rate of group 0 to 8.0000e-02.\n",
      "e: 3 | Train Loss: 91467.4355 | 2.0415 | Acc: 0.7872\n",
      "e: 3 | Valid Loss: 8302.0381 | 2.1002 | Acc: 0.7554\n",
      "Validation loss decreased (8987.483818 --> 8302.038136).\n",
      "Adjusting learning rate of group 0 to 1.0000e-01.\n",
      "e: 4 | Train Loss: 82194.6284 | 1.8345 | Acc: 0.7993\n",
      "e: 4 | Valid Loss: 7661.6352 | 1.9382 | Acc: 0.7647\n",
      "Validation loss decreased (8302.038136 --> 7661.635233).\n",
      "Adjusting learning rate of group 0 to 1.2000e-01.\n",
      "e: 5 | Train Loss: 73196.1758 | 1.6337 | Acc: 0.8141\n",
      "e: 5 | Valid Loss: 7107.0442 | 1.7979 | Acc: 0.7774\n",
      "Validation loss decreased (7661.635233 --> 7107.044174).\n",
      "Adjusting learning rate of group 0 to 1.4000e-01.\n",
      "e: 6 | Train Loss: 66238.1609 | 1.4784 | Acc: 0.8252\n",
      "e: 6 | Valid Loss: 6675.7740 | 1.6888 | Acc: 0.7850\n",
      "Validation loss decreased (7107.044174 --> 6675.774015).\n",
      "Adjusting learning rate of group 0 to 1.6000e-01.\n",
      "e: 7 | Train Loss: 59507.9128 | 1.3282 | Acc: 0.8386\n",
      "e: 7 | Valid Loss: 6348.5684 | 1.6060 | Acc: 0.7938\n",
      "Validation loss decreased (6675.774015 --> 6348.568361).\n",
      "Adjusting learning rate of group 0 to 1.8000e-01.\n",
      "e: 8 | Train Loss: 55178.1915 | 1.2315 | Acc: 0.8463\n",
      "e: 8 | Valid Loss: 6157.5445 | 1.5577 | Acc: 0.7974\n",
      "Validation loss decreased (6348.568361 --> 6157.544456).\n",
      "Adjusting learning rate of group 0 to 2.0000e-01.\n",
      "e: 9 | Train Loss: 51658.2510 | 1.1530 | Acc: 0.8530\n",
      "e: 9 | Valid Loss: 5967.3673 | 1.5096 | Acc: 0.8039\n",
      "Validation loss decreased (6157.544456 --> 5967.367276).\n",
      "Adjusting learning rate of group 0 to 2.2000e-01.\n",
      "e: 10 | Train Loss: 48243.6511 | 1.0767 | Acc: 0.8589\n",
      "e: 10 | Valid Loss: 5867.3218 | 1.4843 | Acc: 0.8052\n",
      "Validation loss decreased (5967.367276 --> 5867.321755).\n",
      "Epoch 00001: adjusting learning rate of group 0 to 2.0000e-01.\n",
      "e: 11 | Train Loss: 46326.6334 | 1.0340 | Acc: 0.8605\n",
      "e: 11 | Valid Loss: 5790.0364 | 1.4647 | Acc: 0.8070\n",
      "Validation loss decreased (5867.321755 --> 5790.036380).\n",
      "Epoch 00002: adjusting learning rate of group 0 to 1.9999e-01.\n",
      "e: 12 | Train Loss: 45453.3904 | 1.0145 | Acc: 0.8633\n",
      "e: 12 | Valid Loss: 5701.0980 | 1.4422 | Acc: 0.8082\n",
      "Validation loss decreased (5790.036380 --> 5701.098003).\n",
      "Epoch 00003: adjusting learning rate of group 0 to 1.9999e-01.\n",
      "e: 13 | Train Loss: 42994.6289 | 0.9596 | Acc: 0.8693\n",
      "e: 13 | Valid Loss: 5645.0839 | 1.4281 | Acc: 0.8131\n",
      "Validation loss decreased (5701.098003 --> 5645.083876).\n",
      "Epoch 00004: adjusting learning rate of group 0 to 1.9998e-01.\n",
      "e: 14 | Train Loss: 42994.5183 | 0.9596 | Acc: 0.8667\n",
      "e: 14 | Valid Loss: 5650.3446 | 1.4294 | Acc: 0.8110\n",
      "Epoch 00005: adjusting learning rate of group 0 to 1.9996e-01.\n",
      "e: 15 | Train Loss: 41093.1117 | 0.9172 | Acc: 0.8723\n",
      "e: 15 | Valid Loss: 5599.9749 | 1.4166 | Acc: 0.8138\n",
      "Validation loss decreased (5645.083876 --> 5599.974942).\n",
      "Epoch 00006: adjusting learning rate of group 0 to 1.9995e-01.\n",
      "e: 16 | Train Loss: 41476.4291 | 0.9257 | Acc: 0.8702\n",
      "e: 16 | Valid Loss: 5590.5919 | 1.4143 | Acc: 0.8143\n",
      "Validation loss decreased (5599.974942 --> 5590.591949).\n",
      "Epoch 00007: adjusting learning rate of group 0 to 1.9993e-01.\n",
      "e: 17 | Train Loss: 40804.6622 | 0.9107 | Acc: 0.8720\n",
      "e: 17 | Valid Loss: 5566.9672 | 1.4083 | Acc: 0.8156\n",
      "Validation loss decreased (5590.591949 --> 5566.967239).\n",
      "Epoch 00008: adjusting learning rate of group 0 to 1.9991e-01.\n",
      "e: 18 | Train Loss: 40165.7526 | 0.8965 | Acc: 0.8722\n",
      "e: 18 | Valid Loss: 5501.6775 | 1.3918 | Acc: 0.8171\n",
      "Validation loss decreased (5566.967239 --> 5501.677483).\n",
      "Epoch 00009: adjusting learning rate of group 0 to 1.9988e-01.\n",
      "e: 19 | Train Loss: 40172.9879 | 0.8966 | Acc: 0.8718\n",
      "e: 19 | Valid Loss: 5494.4500 | 1.3899 | Acc: 0.8163\n",
      "Validation loss decreased (5501.677483 --> 5494.450037).\n",
      "Epoch 00010: adjusting learning rate of group 0 to 1.9985e-01.\n",
      "e: 20 | Train Loss: 39451.4619 | 0.8805 | Acc: 0.8742\n",
      "e: 20 | Valid Loss: 5494.3121 | 1.3899 | Acc: 0.8171\n",
      "Validation loss decreased (5494.450037 --> 5494.312114).\n",
      "Epoch 00011: adjusting learning rate of group 0 to 1.9982e-01.\n",
      "e: 21 | Train Loss: 38586.2836 | 0.8612 | Acc: 0.8747\n",
      "e: 21 | Valid Loss: 5501.1737 | 1.3916 | Acc: 0.8176\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "from src.train import run_linearprotocol, run_test\n",
    "\n",
    "\n",
    "wandb.init(name=RUN_NAME, project=WANDB_PRJ, config=CONFIG, reinit=True)\n",
    "\n",
    "run_linearprotocol(model, mlp, dataloaders, dataset_sizes,\n",
    "                   optimizer, criterion, warmupscheduler, mainscheduler, device, RUN_NAME, SAVE_PATH)\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = timm.create_model('resnet50', pretrained=False, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "mlp = MLP(num_classes=17)\n",
    "mlp.load_state_dict(torch.load(f'{SAVE_PATH}/{RUN_NAME}-MLP-best_model.pth'))  \n",
    "\n",
    "run_test(model, mlp, dataloaders, dataset_sizes, criterion, device)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ff78b-2294-4248-ad1d-1e8939716cb7",
   "metadata": {},
   "source": [
    "-------\n",
    "### SupCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b7a96-aee8-499f-8b16-0ee0d656f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 333\n",
    "seed_everything(SEED)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "MODEL_PATH = '../../../pretrained/ResNet50-SupCL-33+300-400.pth'\n",
    "SAVE_PATH = '../../../weights'\n",
    "\n",
    "RUN_NAME = 'ResNet50-SupCL-33-400-linear'\n",
    "WANDB_PRJ = 'DeepFashion-pre-linear'\n",
    "\n",
    "CONFIG = {\n",
    "    \"dataset\": \"DeepFashion\",\n",
    "    \"machine\": \"offline cluster\",\n",
    "    \"model\": \"ResNet50-SupCL\",\n",
    "    \"learning_rate\": 0.2,\n",
    "    \"batch_size\": batch_size*2\n",
    "}\n",
    "\n",
    "print(f'Training on {device} - {WANDB_PRJ} / {RUN_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e188231-2acf-45b5-99fa-f06f4c6df8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.models import MLP\n",
    "from src.optim_lars import LARS\n",
    "\n",
    "num_classes = 0\n",
    "model = timm.create_model('resnet50', pretrained=False, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "mlp = MLP(num_classes=17) \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = LARS(\n",
    "    list(mlp.parameters()),\n",
    "    lr=0.2,\n",
    "    weight_decay=1e-6,\n",
    "    exclude_from_weight_decay=['batch_normalization', 'bias'],\n",
    ")\n",
    "\n",
    "warmupscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch : (epoch+1)/10.0, verbose = True)\n",
    "mainscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 500, eta_min=0.05, last_epoch=-1, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc04a6a-b91a-43cd-a355-d47c3499023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "from src.train import run_linearprotocol, run_test\n",
    "\n",
    "\n",
    "wandb.init(name=RUN_NAME, project=WANDB_PRJ, config=CONFIG, reinit=True)\n",
    "\n",
    "run_linearprotocol(model, mlp, dataloaders, dataset_sizes,\n",
    "                   optimizer, criterion, warmupscheduler, mainscheduler, device, RUN_NAME, SAVE_PATH)\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = timm.create_model('resnet50', pretrained=False, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "mlp = MLP(num_classes=17)\n",
    "mlp.load_state_dict(torch.load(f'{SAVE_PATH}/{RUN_NAME}-MLP-best_model.pth'))  \n",
    "\n",
    "run_test(model, mlp, dataloaders, dataset_sizes, criterion, device)\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soohee_env",
   "language": "python",
   "name": "soohee_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
